{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport requests                 \nfrom bs4 import BeautifulSoup    \nimport nltk                      \nfrom collections import Counter\n\n\n# Fetch HTML content from the given URL\nresponse = requests.get(\"https://www.gutenberg.org/files/16/16-h/16-h.htm\")\n\n\nresponse.encoding = 'utf-8'\n\n# Extract HTML content\nhtml_content = response.text\n\n# Parse the HTML using BeautifulSoup\nsoup = BeautifulSoup(html_content, \"html.parser\")\n\n# Extract the textual content from the parsed HTML\nfull_text = soup.get_text()\n\n\n# Create a tokenizer instance\nregex_tokenizer = nltk.RegexpTokenizer(r\"\\w+\")\n\n# Tokenize the extracted text into words\ntokens = regex_tokenizer.tokenize(full_text)\n\n\n# Convert tokens to lowercase\nnormalized_words = [token.lower() for token in tokens]\n\n# Download stop words if not already downloaded\nnltk.download(\"stopwords\")\n\n# Retrieve the list of English stop words\nstopwords = nltk.corpus.stopwords.words(\"english\")\n\n\n# Remove stop words from the tokenized list\nfiltered_words = [word for word in normalized_words if word not in stopwords]\n\n\n# Create a Counter to count word frequencies\nword_counts = Counter(filtered_words)\n\n# Get the 10 most common words\nmost_common_words = word_counts.most_common(10)\n\n# Print the results\nprint(\"Top 10 most common words:\", most_common_words)\n\n# Protagonist names among the most common words\nprotagonists = [\"peter\", \"wendy\", \"hook\", \"john\"]\n\nprint(\"Protagonists:\", protagonists)\n","execution_count":1,"outputs":[{"output_type":"stream","text":"[nltk_data] Downloading package stopwords to /home/repl/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\nTop 10 most common words: [('peter', 409), ('wendy', 362), ('said', 358), ('would', 217), ('one', 212), ('hook', 174), ('could', 142), ('cried', 136), ('john', 133), ('time', 126)]\nProtagonists: ['peter', 'wendy', 'hook', 'john']\n","name":"stdout"}]},{"metadata":{"dc":{"key":"3"},"deletable":false,"editable":false,"run_control":{"frozen":true},"tags":["context"]},"cell_type":"markdown","source":"## # Introduction\n<p><img src=\"https://assets.datacamp.com/production/project_1010/img/book_cover.jpg\" alt=\"The book cover of Peter and Wendy\" style=\"width:183;height:253px;\"></p>\n<h3 id=\"flyawaywithpeterpan\">Fly away with Peter Pan!</h3>\n<p>Peter Pan has been the companion of many children, and went a long way, starting as a Christmas play and ending up as a Disney classic. Did you know that although the play was titled \"Peter Pan, Or The Boy Who Wouldn't Grow Up\", J. M. Barrie's novel was actually titled \"Peter and Wendy\"? </p>\n<p>You're going to explore and analyze Peter Pan's text to answer the question in the instruction pane below. You are working with the text version available here at <a href=\"https://www.gutenberg.org/files/16/16-h/16-h.htm\">Project Gutenberg</a>. Feel free to add as many cells as necessary. Finally, remember that you are only tested on your answer, not on the methods you use to arrive at the answer!</p>\n<p><strong>Note:</strong> If you haven't completed a DataCamp project before you should check out the <a href=\"https://projects.datacamp.com/projects/33\">Intro to Projects</a> first to learn about the interface. <a href=\"https://www.datacamp.com/courses/intermediate-importing-data-in-python\">Intermediate Importing Data in Python</a> and <a href=\"https://www.datacamp.com/courses/introduction-to-natural-language-processing-in-python\">Introduction to Natural Language Processing in Python</a> teach the skills required to complete this project. Should you decide to use them, English stopwords have been downloaded from <code>nltk</code> and are available for you in your environment.</p>"}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.6.7","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":2}